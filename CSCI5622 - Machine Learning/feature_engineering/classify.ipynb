{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label set: ['False', 'True']\n",
      "(14784, 14784)\n",
      "set([0, 1])\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader, DictWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import nltk\n",
    "\n",
    "kTARGET_FIELD = 'spoiler'\n",
    "kTEXT_FIELD = 'sentence'\n",
    "\n",
    "def f(examples):\n",
    "    ex = []\n",
    "    for sent in examples:\n",
    "        newSent = nltk.pos_tag(sent.split())\n",
    "        ex.append(\" \".join([i[0] + \":\" + i[1] for i in newSent]))\n",
    "#         ex.append(\" \".join([i[1] for i in newSent]))\n",
    "    print(ex[0])\n",
    "    return ex\n",
    "\n",
    "def get_lists(examples):\n",
    "    base_examples = list(examples)\n",
    "    tags_examples = [] # For nltk based features\n",
    "    for sent in base_examples:\n",
    "        newSent = list(nltk.pos_tag(sent.split()))\n",
    "        tags_examples.append(newSent)\n",
    "    return base_examples, tags_examples\n",
    "    \n",
    "def get_pos_only(examples):\n",
    "    pos_examples = []\n",
    "    for sent in examples:\n",
    "        newSent = \" \".join(sent[x][1] for x in range(len(sent)))\n",
    "        #print(newSent)\n",
    "        pos_examples.append(newSent)\n",
    "    return pos_examples\n",
    "\n",
    "def get_words_pos(examples):\n",
    "    words_pos = []\n",
    "    for sent in examples:\n",
    "        newSent = \" \".join(\"%s(%s)\" % (sent[x][0].replace(\".\",\"\"), sent[x][1]) for x in range(len(sent)))\n",
    "        #print(newSent)\n",
    "        words_pos.append(newSent)\n",
    "    return words_pos\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "class Featurizer:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(ngram_range=(1,3), token_pattern = \"[a-zA-Z]+(\\([a-zA-Z]+\\))?\")\n",
    "\n",
    "    def train_feature(self, examples):\n",
    "        base_examples, tags_examples = get_lists(examples)\n",
    "            \n",
    "        # Fit examples containing only pos tags\n",
    "        pos_only = get_pos_only(tags_examples)\n",
    "        #self.vectorizer.fit(pos_only)\n",
    "        \n",
    "        #Fit examples containing word pos-tag pairs\n",
    "        words_pos = get_words_pos(tags_examples)\n",
    "        #self.vectorizer.fit(words_pos)\n",
    "        ex = [\" \".join([base_examples[x],pos_only[x],words_pos[x]]) for x in range(len(base_examples))]\n",
    "        \n",
    "        #print(ex)\n",
    "        \n",
    "        return self.vectorizer.fit_transform(ex)\n",
    "\n",
    "    def test_feature(self, examples):\n",
    "        base_examples, tags_examples = get_lists(examples)\n",
    "        pos_only = get_pos_only(tags_examples)\n",
    "        words_pos = get_words_pos(tags_examples)\n",
    "        ex = [\" \".join([base_examples[x],pos_only[x],words_pos[x]]) for x in range(len(base_examples))]\n",
    "        return self.vectorizer.transform(ex)\n",
    "\n",
    "    def show_top10(self, classifier, categories):\n",
    "        feature_names = np.asarray(self.vectorizer.get_feature_names())\n",
    "        if len(categories) == 2:\n",
    "            top10 = np.argsort(classifier.coef_[0])[-10:]\n",
    "            bottom10 = np.argsort(classifier.coef_[0])[:10]\n",
    "            print(\"Pos: %s\" % \" - \".join(feature_names[top10]))\n",
    "            print(\"Neg: %s\" % \" - \".join(feature_names[bottom10]))\n",
    "        else:\n",
    "            for i, category in enumerate(categories):\n",
    "                top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "                print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "\n",
    "# Cast to list to keep it all in memory\n",
    "trainset = list(DictReader(open(\"../data/spoilers/train.csv\", 'r')))\n",
    "test = list(DictReader(open(\"../data/spoilers/test.csv\", 'r')))\n",
    "\n",
    "# Split training data into train validate and holdout sets\n",
    "# n = len(trainset)\n",
    "# shuffle(trainset)\n",
    "# train = trainset[:8*n//10]\n",
    "# validate = trainset[6*n//10:8*n//10]\n",
    "# h_out = trainset[8*n//10:]\n",
    "# train = trainset[:100]\n",
    "train = trainset\n",
    "\n",
    "feat = Featurizer()\n",
    "\n",
    "labels = []\n",
    "for line in train:\n",
    "    if not line[kTARGET_FIELD] in labels:\n",
    "        labels.append(line[kTARGET_FIELD])\n",
    "\n",
    "print(\"Label set: %s\" % str(labels))\n",
    "x_train = feat.train_feature(x[kTEXT_FIELD] for x in train)\n",
    "x_test = feat.test_feature(x[kTEXT_FIELD] for x in test)\n",
    "# x_validate = feat.test_feature(x[kTEXT_FIELD] for x in validate)\n",
    "# x_h_out = feat.test_feature(x[kTEXT_FIELD] for x in h_out)\n",
    "\n",
    "y_train = array(list(labels.index(x[kTARGET_FIELD])\n",
    "                     for x in train))\n",
    "\n",
    "print(len(train), len(y_train))\n",
    "print(set(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1477, 9166)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: (cc) - (vbz) -  (nn) (vbd) -  (nn) - (nn)  - (nnp) -  (nnp) (nn) -   (jj) -    - (rp)\n",
      "Neg: (nnp) (nnp) -   (nnp) - (nn) -   - (jj) -  (nnp) (nnp) - (vbp) - (jjr) - (nn) (nnp) - (jj) (nns)\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "lr = SGDClassifier(loss='log', penalty='l2', shuffle=True)\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "feat.show_top10(lr, labels)\n",
    "\n",
    "predictions = lr.predict(x_test)\n",
    "o = DictWriter(open(\"predictions.csv\", 'w'), [\"Id\", \"spoiler\"])\n",
    "o.writeheader()\n",
    "for ii, pp in zip([x['Id'] for x in test], predictions):\n",
    "    d = {'Id': ii, 'spoiler': labels[pp]}\n",
    "    o.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 8630 features per sample; expecting 9166",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-eec9442a2a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_validate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spoiler\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"True\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_validate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/r1413/anaconda3/envs/python2_7/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/r1413/anaconda3/envs/python2_7/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 317\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 8630 features per sample; expecting 9166"
     ]
    }
   ],
   "source": [
    "pred_validate = lr.predict(x_validate)\n",
    "y_validate = []\n",
    "for i in validate:\n",
    "    if(i[\"spoiler\"] == \"True\"): y_validate.append(1)\n",
    "    else: y_validate.append(0)\n",
    "# print(pred_validate)\n",
    "# print(y_validate)\n",
    "count = 0\n",
    "for i in range(len(validate)):\n",
    "    if(pred_validate[i] == y_validate[i]): \n",
    "        count += 1       \n",
    "print(float(count)/len(validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.523165370308\n"
     ]
    }
   ],
   "source": [
    "pred_h_out = lr.predict(x_validate)\n",
    "y_h_out = []\n",
    "for i in h_out:\n",
    "    if(i[\"spoiler\"] == \"True\"): y_h_out.append(1)\n",
    "    else: y_h_out.append(0)\n",
    "        \n",
    "count = 0\n",
    "for i in range(len(h_out)):\n",
    "    if(pred_h_out[i] == y_h_out[i]): \n",
    "        count += 1       \n",
    "print(float(count)/len(h_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2_7]",
   "language": "python",
   "name": "Python [python2_7]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
